---
title: "Replication of Study 2 from Human heuristics for AI-generated language are flawed (PNAS) by Jakesch et al. 2023"
author: "Cid Decatur (cdecatur@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

Generative language models mediate communicative processes with humans and the psychological mechanisms of AI-mediated communication (AI-MC). People use AI to autocomplete or craft entire messages for their digitally communicative practices. My research program revolves around understanding how humans construct the identity of themselves and others with media (AI is of growing interest). As identity becomes psychologically salient while crafting a message online, we know communicators are likelier to bend or break the truth about themselves. AI plagiarism of a dating profile bio is unique in that the content of the message may be factually correct, yet the credit for compositional skill and cues given off from the AI-generated bio take advantage of pretenses. This study will verify the accuracy with which message receivers can identify AI-plagiarized biographies. Attempting to replicate this study will bring me up to speed on managing the analytic chain of research and allow me to get my hands dirty with collecting and analyzing crowd worker data for the first time. The methods of analysis and statistics computed for the study are also challenging to me but not outside of my potential capability for the next eight weeks.

### Justification 

Generative language models mediate communicative processes with humans and the psychological mechanisms of AI-mediated communication (AI-MC). People use AI to autocomplete or craft entire messages for their digitally communicative practices. My research program revolves around understanding how humans construct the identity of themselves and others with media (AI is of growing interest). As identity becomes psychologically salient while crafting a message online, we know communicators are likelier to bend or break the truth about themselves. AI plagiarism of a dating profile bio is unique in that the content of the message may be factually correct, yet the credit for compositional skill and cues given off from the AI-generated bio take advantage of pretenses. This study will verify the accuracy with which message receivers can identify AI-plagiarized biographies. Attempting to replicate this study will bring me up to speed on managing the analytic chain of research and allow me to get my hands dirty with collecting and analyzing crowd worker data for the first time. The methods of analysis and statistics computed for the study are also challenging to me but not outside of my potential capability for the next eight weeks.

### Stimuli and Procedure 

The stimuli for this project are not publically available but are retrievable from my advisor and co-author on the original project, Jeffrey Hancock. The project has a repository with all data and procedures available on OSF. The supplemental materials that describe data-collection procedures for the six studies in the original paper are in this directory.

The procedure for this experiment is relatively straightforward, using the AI-generated messages provided by the original authors. If training and scraping a new set of stimuli becomes more appropriate, this would be outside of my current skillset but would be possible if I wanted to take the paper to publication. The original study recruited 1,000 gender-balanced participants on Prolific and sampled from 1,000 user-generated dating bios and 1,000 AI-generated dating bios. They then briefed the participants on their task to identify the bios generated by AI, which they completed in a digital format. 

Regarding challenges, I’ve never run an experiment by myself from start to finish, nor have I been the sole analyst on a dataset. Conducting the statistical analysis, managing the analytic pipeline, and keeping data organized by myself without the help of others will be enough of a challenge for me. If I’m completing the project with too much ease, I’ll find ways to produce a more complete and challenging procedure. 

### Links 

Repository: <https://github.com/psych251/jakesch2023>

Original paper: <https://github.com/psych251/jakesch2023/blob/main/original_paper/Jakesch%20et%20al.%2C%202023.pdf>

Supplemental material: <https://github.com/psych251/jakesch2023/blob/main/original_paper/pnas.2208839120.sapp.pdf>

## Methods

Materials and Methods
**From Jakesch 2023** "Experiment Design. The six experiments combined elements of a simplified Turing test (21) with a data labeling task. After providing informed consent, participants were introduced to the hospitality, dating, or professional scenario. They were told that they were browsing an online platform where some users had written their self-presentations while an AI system generated other self-presentations. Participants completed two comprehension checks and rated 16 self-presentations, half generated by a state-of-the-art AI language model. They were asked to evaluate whether each self-presentation was generated by AI on a five-point Likert scale from “definitely AI-generated” to “definitely human-written.” Mirroring truth default behaviors observed in deception research (34), participants marked the self-presentations as “likely human-written” or “definitely human-written” in 53.8% of cases. In the remaining 46.2% of cases, they showed suspicion and selected either “not sure,” “likely AI-generated,” or “definitely AI-generated.” To allow for concise analysis, we used these two roughly balanced groups to create a binary signal corresponding to participants’ suspicion that a self-presentation may not be human-written. A robustness check using the full scale as the primary outcome metric showed similar results. Halfway through the rating task, participants in the three main experiments were asked to explain their judgment in an open-ended response. Asking participants to explain their reasoning did not change the accuracy of their subsequent ratings (see SI Appendix for details). Following the rating task, participants provided demographic information and indicated their experience with computer programming and AI technologies. Participants were debriefed about their performance and the purpose of the study. The Cornell University Institutional Review Board approved the study protocols. We preregistered the final two validation experiments prior to data collection (https://aspredicted.org/bz7x7.pdf).
We performed the experiments in three social contexts to increase robustness and generalizability. In addition, minor variations across experiments explored auxiliary hypotheses. We used longer self-presentations in the dating and professional-context experiments to test whether the length of self-presentations limited participants' accuracy. To keep the three main experiments’ duration comparable, we reduced the number of rated self-presentations to 12 in these two experiments. To explore the effect of increased effort (23), we offered half of the participants in the dating context a bonus payment if they rated at least 75% of the self-presentations correctly. There was no difference in performance between the bonus and no-bonus groups. Finally, to test whether participants could learn to detect generated self-presentations if they received feedback (18), half of the participants in the professional context were told whether their choice was correct after every rating, again with no difference in outcomes. An overview of the experimental designs is included in SI Appendix."



**Modifications**



The authors note that they used 2,000 participants for the original experiment with the hospitality context. They note that a sample size of 1,000 is good enough for replication at end of PNAS report.

Each participant reads 12 self-descriptions, half AI-generated, and half-human-written, sampled from an *anonymized* set of profile bios and paired.

### Power Analysis



### Planned Sample



### Materials

"Four cases were selected from the corpus of videos first reported by Horvath, Jayne, and Buckley (1994). Each of these cases involved an employee theft of money from an employer. The cases were selected because they each contained two and only two primary suspects. One of the suspects was deceptive (guilty) and one was truthful (innocent) in each case as established by the evidence-corroborated confession of the deceptive party (see Horvath et al., 1994, for more information on the videos). From the four cases, two truthful and two deceptive suspects were randomly selected and placed in random order on a video; thus, participants saw only one of the two prime suspects from each case."

This will be adopted to an alread-validated set of social media news-headlines posts, 20 true and 20 false. 

Topics range civic issues, health, politics, science and technology. 

I anticipate needing a larger sample size than 40. The adapted study reported effect sizes of d=1.2 and d=1.4.


### Procedure	

"Twenty-five students (60% females, mean age = 27.6, SD = 9.7) at a large university in the southwestern United States were randomly placed into either the context (n = 13) or the control group (n = 12). Participants in the context group received a case file that contained a brief summary of the background of the prime suspects and the general scenario regarding the missing money. They were instructed to read the case file prior to viewing the relevant video. Participants in the no-context group did not receive this information. Both groups viewed the videos and rendered dichotomous truth–deception judgments."

**For replication** the sample size will likely be more than twice as big than the original authors, and will be as closed to representative as possible in regard to gender and similar demographics. 

Procedure will vary only around stimuli, replacing deception videos with misinformation-possible Twitter posts. 

### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Key analysis: two-tailed, two-sample t-test. (Potential Bayesian factor analysis)**

With accuracy data collected through Prolific/Qualtrics: 

1) Run python script to anonymize data. 

2) Filter for: Treatment group true news accuracy, treatment false news accuracy, control group true news accuracy, treatment false news accuracy. 

3) Run two-sample, two-tailed t-tests for each accuracy type and each treatment. 

Data cleaning rules: this should be straightforward. This should be analyzed with TaT. It's likely that all participants that start the study will finish it. No identifying data is required. 


### Differences from Original Study



### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
