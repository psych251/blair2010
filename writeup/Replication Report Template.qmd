---
title: "Replication of Study 2 from Human heuristics for AI-generated language are flawed (PNAS) by Jakesch et al. 2023"
author: "Cid Decatur (cdecatur@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

Generative language models mediate communicative processes with humans and the psychological mechanisms of AI-mediated communication (AI-MC). People use AI to autocomplete or craft entire messages for their digitally communicative practices. My research program revolves around understanding how humans construct the identity of themselves and others with media (AI is of growing interest). As identity becomes psychologically salient while crafting a message online, we know communicators are likelier to bend or break the truth about themselves. AI plagiarism of a dating profile bio is unique in that the content of the message may be factually correct, yet the credit for compositional skill and cues given off from the AI-generated bio take advantage of pretenses. This study will verify the accuracy with which message receivers can identify AI-plagiarized biographies. Attempting to replicate this study will bring me up to speed on managing the analytic chain of research and allow me to get my hands dirty with collecting and analyzing crowd worker data for the first time. The methods of analysis and statistics computed for the study are also challenging to me but not outside of my potential capability for the next eight weeks.

### Justification 

Generative language models mediate communicative processes with humans and the psychological mechanisms of AI-mediated communication (AI-MC). People use AI to autocomplete or craft entire messages for their digitally communicative practices. My research program revolves around understanding how humans construct the identity of themselves and others with media (AI is of growing interest). As identity becomes psychologically salient while crafting a message online, we know communicators are likelier to bend or break the truth about themselves. AI plagiarism of a dating profile bio is unique in that the content of the message may be factually correct, yet the credit for compositional skill and cues given off from the AI-generated bio take advantage of pretenses. This study will verify the accuracy with which message receivers can identify AI-plagiarized biographies. Attempting to replicate this study will bring me up to speed on managing the analytic chain of research and allow me to get my hands dirty with collecting and analyzing crowd worker data for the first time. The methods of analysis and statistics computed for the study are also challenging to me but not outside of my potential capability for the next eight weeks.

### Stimuli and Procedure 

The stimuli for this project are not publically available but are retrievable from my advisor and co-author on the original project, Jeffrey Hancock. The project has a repository with all data and procedures available on OSF. The supplemental materials that describe data-collection procedures for the six studies in the original paper are in this directory.

The procedure for this experiment is relatively straightforward, using the AI-generated messages provided by the original authors. If training and scraping a new set of stimuli becomes more appropriate, this would be outside of my current skillset but would be possible if I wanted to take the paper to publication. The original study recruited 1,000 gender-balanced participants on Prolific and sampled from 1,000 user-generated dating bios and 1,000 AI-generated dating bios. They then briefed the participants on their task to identify the bios generated by AI, which they completed in a digital format. 

Regarding challenges, I’ve never run an experiment by myself from start to finish, nor have I been the sole analyst on a dataset. Conducting the statistical analysis, managing the analytic pipeline, and keeping data organized by myself without the help of others will be enough of a challenge for me. If I’m completing the project with too much ease, I’ll find ways to produce a more complete and challenging procedure. 

### Links 

Repository: <https://github.com/psych251/jakesch2023>

Original paper: <https://github.com/psych251/jakesch2023/blob/main/original_paper/Jakesch%20et%20al.%2C%202023.pdf>

Supplemental material: <https://github.com/psych251/jakesch2023/blob/main/original_paper/pnas.2208839120.sapp.pdf>

## Methods

From paper: "We trained multiple customized versions of state-of-the-art AI language models (1, 2, 4) to generate self-presentations in three social contexts where trust in a self-presentation is important for decision-making: professional (e.g., job applications) (22), romantic (e.g., online dating) (12), and hospitality services (e.g., Airbnb host profiles) (15). Across three main and three validation experiments, we asked 4,600 participants to read through a total of 7,600 self-presentations—some AI-generated and some collected from real-world online platforms—and indicate which ones they thought were generated by AI.
We start by computing the accuracy rates for participants’ ability to distinguish between human and AI-generated self-presentations. In our three main experiments, using two different language models to generate verbal self-presentations across three social contexts, participants identified the source of a self-presentation with only 50 to 52% accuracy. These results, with a breakdown by experiments and treatments, are shown in Fig. 1. In the hospitality context (shown in the Left panel), participants correctly identified the source of a self-presentation 52.2% of the time. In the dating context, we introduced experimental treatments testing whether incentivizing participants to increase their efforts (23) would increase their accuracy. In the professional context, we tested whether providing training (18) in the form of feedback would improve participants’ judgments. However, participants’ accuracy remained close to chance even when offered monetary incentives for accurate assessments (right bar in the second panel in Fig. 1, 51.6%) and when receiving immediate feedback on their evaluations (right bar in the third panel, 51.2%). Further analyses (included in SI Appendix) revealed that no demographic group performed better than others."

### Power Analysis



### Planned Sample



### Materials

"Four cases were selected from the corpus of videos first reported by Horvath, Jayne, and Buckley (1994). Each of these cases involved an employee theft of money from an employer. The cases were selected because they each contained two and only two primary suspects. One of the suspects was deceptive (guilty) and one was truthful (innocent) in each case as established by the evidence-corroborated confession of the deceptive party (see Horvath et al., 1994, for more information on the videos). From the four cases, two truthful and two deceptive suspects were randomly selected and placed in random order on a video; thus, participants saw only one of the two prime suspects from each case."

This will be adopted to an alread-validated set of social media news-headlines posts, 20 true and 20 false. 

Topics range civic issues, health, politics, science and technology. 

I anticipate needing a larger sample size than 40. The adapted study reported effect sizes of d=1.2 and d=1.4.


### Procedure	

"Twenty-five students (60% females, mean age = 27.6, SD = 9.7) at a large university in the southwestern United States were randomly placed into either the context (n = 13) or the control group (n = 12). Participants in the context group received a case file that contained a brief summary of the background of the prime suspects and the general scenario regarding the missing money. They were instructed to read the case file prior to viewing the relevant video. Participants in the no-context group did not receive this information. Both groups viewed the videos and rendered dichotomous truth–deception judgments."

**For replication** the sample size will likely be more than twice as big than the original authors, and will be as closed to representative as possible in regard to gender and similar demographics. 

Procedure will vary only around stimuli, replacing deception videos with misinformation-possible Twitter posts. 

### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Key analysis: two-tailed, two-sample t-test. (Potential Bayesian factor analysis)**

With accuracy data collected through Prolific/Qualtrics: 

1) Run python script to anonymize data. 

2) Filter for: Treatment group true news accuracy, treatment false news accuracy, control group true news accuracy, treatment false news accuracy. 

3) Run two-sample, two-tailed t-tests for each accuracy type and each treatment. 

Data cleaning rules: this should be straightforward. This should be analyzed with TaT. It's likely that all participants that start the study will finish it. No identifying data is required. 


### Differences from Original Study



### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
